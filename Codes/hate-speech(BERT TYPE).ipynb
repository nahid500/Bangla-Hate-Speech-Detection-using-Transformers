{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8407735,"sourceType":"datasetVersion","datasetId":5003406},{"sourceId":8637304,"sourceType":"datasetVersion","datasetId":5172324}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets torch accelerate -U\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom datasets import load_dataset\n\ndataset = load_dataset('csv', data_files={'train': '/kaggle/input/typeofhate/type_train.csv', 'test': '/kaggle/input/typeofhate/encoded_test.csv'})\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:00:30.503104Z","iopub.execute_input":"2024-06-08T09:00:30.503488Z","iopub.status.idle":"2024-06-08T09:00:30.644824Z","shell.execute_reply.started":"2024-06-08T09:00:30.503458Z","shell.execute_reply":"2024-06-08T09:00:30.643858Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Choose the model checkpoint (BERT or RoBERTa that supports Bangla, such as 'bert-base-multilingual-cased')\nmodel_checkpoint = \"bert-base-multilingual-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\ndef tokenize_function(examples):\n    # Tokenize the text\n    tokenized_inputs = tokenizer(examples['sentence'], padding=\"max_length\", truncation=True, max_length=512)\n    \n    # Include the labels\n    tokenized_inputs['labels'] = examples['hate speech']\n    \n    return tokenized_inputs\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:00:32.401658Z","iopub.execute_input":"2024-06-08T09:00:32.402462Z","iopub.status.idle":"2024-06-08T09:00:35.000455Z","shell.execute_reply.started":"2024-06-08T09:00:32.402433Z","shell.execute_reply":"2024-06-08T09:00:34.999559Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5029 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89f12e22781b418090b60ea245eec9e0"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nnum_labels = 16  \nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:00:35.762560Z","iopub.execute_input":"2024-06-08T09:00:35.762937Z","iopub.status.idle":"2024-06-08T09:00:40.072889Z","shell.execute_reply.started":"2024-06-08T09:00:35.762908Z","shell.execute_reply":"2024-06-08T09:00:40.072100Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b25604bde611461299daa503c3f14bc2"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    save_total_limit=1,\n    report_to = 'none',\n    load_best_model_at_end=True,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:01:21.758637Z","iopub.execute_input":"2024-06-08T09:01:21.758993Z","iopub.status.idle":"2024-06-08T09:01:21.790197Z","shell.execute_reply.started":"2024-06-08T09:01:21.758966Z","shell.execute_reply":"2024-06-08T09:01:21.789462Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:13:29.277719Z","iopub.execute_input":"2024-05-31T13:13:29.278627Z","iopub.status.idle":"2024-05-31T13:13:29.283453Z","shell.execute_reply.started":"2024-05-31T13:13:29.278584Z","shell.execute_reply":"2024-05-31T13:13:29.282143Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\naccuracy_metric = load_metric(\"accuracy\")\nprecision_metric = load_metric(\"precision\")\nrecall_metric = load_metric(\"recall\")\nf1_metric = load_metric(\"f1\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(-1)\n    \n    # Calculate all metrics\n    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n    precision = precision_metric.compute(predictions=predictions, references=labels, average='weighted')\n    recall = recall_metric.compute(predictions=predictions, references=labels, average='weighted')\n    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n    \n    return {\n        \"accuracy\": accuracy[\"accuracy\"],\n        \"precision\": precision[\"precision\"],\n        \"recall\": recall[\"recall\"],\n        \"f1\": f1[\"f1\"]\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:00:51.990044Z","iopub.execute_input":"2024-06-08T09:00:51.990426Z","iopub.status.idle":"2024-06-08T09:00:53.753789Z","shell.execute_reply.started":"2024-06-08T09:00:51.990397Z","shell.execute_reply":"2024-06-08T09:00:53.752912Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3164243223.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  accuracy_metric = load_metric(\"accuracy\")\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8227235756994ecf9059c692add30749"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/precision/precision.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05aad1667d3647de9b31c796686b5b15"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/recall/recall.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e13e6457f98b4f99a6823e705df75dea"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0db5aebba99248c8887c9c83c715f44b"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import Trainer, DefaultDataCollator\n\ndata_collator = DefaultDataCollator(return_tensors=\"pt\")\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets['train'],\n    eval_dataset=tokenized_datasets['test'],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:01:26.006962Z","iopub.execute_input":"2024-06-08T09:01:26.007679Z","iopub.status.idle":"2024-06-08T11:59:13.571457Z","shell.execute_reply.started":"2024-06-08T09:01:26.007646Z","shell.execute_reply":"2024-06-08T11:59:13.570524Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024-06-08 09:01:27.532545: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-08 09:01:27.532651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-08 09:01:27.641400: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6285' max='6285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6285/6285 2:57:33, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.311000</td>\n      <td>0.272223</td>\n      <td>0.897196</td>\n      <td>0.897441</td>\n      <td>0.897196</td>\n      <td>0.897227</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.246600</td>\n      <td>0.267783</td>\n      <td>0.900577</td>\n      <td>0.902277</td>\n      <td>0.900577</td>\n      <td>0.900604</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.206400</td>\n      <td>0.251322</td>\n      <td>0.909127</td>\n      <td>0.909418</td>\n      <td>0.909127</td>\n      <td>0.909156</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.159200</td>\n      <td>0.274622</td>\n      <td>0.907536</td>\n      <td>0.908076</td>\n      <td>0.907536</td>\n      <td>0.907571</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.127000</td>\n      <td>0.305998</td>\n      <td>0.903162</td>\n      <td>0.904347</td>\n      <td>0.903162</td>\n      <td>0.903196</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6285, training_loss=0.21526377092966886, metrics={'train_runtime': 10657.387, 'train_samples_per_second': 18.87, 'train_steps_per_second': 0.59, 'total_flos': 5.292091568504832e+16, 'train_loss': 0.21526377092966886, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"results = trainer.evaluate()\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T11:59:22.813460Z","iopub.execute_input":"2024-06-08T11:59:22.814144Z","iopub.status.idle":"2024-06-08T12:01:01.357182Z","shell.execute_reply.started":"2024-06-08T11:59:22.814114Z","shell.execute_reply":"2024-06-08T12:01:01.356144Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='158' max='158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [158/158 01:37]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.2513217329978943, 'eval_accuracy': 0.9091270630344005, 'eval_precision': 0.9094180713281026, 'eval_recall': 0.9091270630344005, 'eval_f1': 0.9091557583421215, 'eval_runtime': 98.5348, 'eval_samples_per_second': 51.038, 'eval_steps_per_second': 1.603, 'epoch': 5.0}\n","output_type":"stream"}]}]}